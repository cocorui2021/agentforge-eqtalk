import os
from openai import AzureOpenAI
from dotenv import load_dotenv

load_dotenv(dotenv_path=".env")

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)

def suggest_replies_from_text(chat_history: str, style="æ¸©æŸ”é£", max_suggestions=3):
    prompt = f"""
ä»¥ä¸‹æ˜¯ç”¨æˆ·ä¸Šä¼ çš„èŠå¤©å†…å®¹ï¼š

{chat_history}

è¯·ä½ åŸºäºè¿™äº›å¯¹è¯ï¼Œåˆ¤æ–­å½“å‰çš„æƒ…ç»ªå¼ åŠ›ä¸æ²Ÿé€šçŠ¶æ€ï¼Œç”Ÿæˆ{max_suggestions}æ¡â€œè‡ªç„¶ã€äººè¯´è¯é£æ ¼â€çš„é«˜æƒ…å•†å›åº”å»ºè®®ã€‚
æ¯æ¡æ§åˆ¶åœ¨25å­—ä»¥å†…ï¼ŒåƒèŠå¤©ä¸­çš„è¯ï¼Œä¸è¦è®²é“ç†ã€‚
æ ¼å¼å¦‚ä¸‹ï¼š

1. å›å¤å†…å®¹ï¼ˆâ­â­â­â­â­ / æ¨èç†ç”±ï¼‰
"""

    response = client.chat.completions.create(
        model=os.getenv("AZURE_DEPLOYMENT_NAME"),
        messages=[
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªæƒ…å•†å¾ˆé«˜çš„èŠå¤©AIï¼Œè¯´è¯è‡ªç„¶æ¥åœ°æ°”ï¼Œä¸è¦ç”¨ä¹¦é¢è¯­æˆ–æ€»ç»“æ€§è¯­è¨€ã€‚"
            },
            {
                "role": "user",
                "content": prompt
            }
        ],
        temperature=0.6,
        max_tokens=300
    )
    return response.choices[0].message.content


if __name__ == "__main__":
    chat = """
æˆ‘ï¼šä½ æœ€è¿‘è€ä¸å›æˆ‘ã€‚
å¥¹ï¼šæˆ‘å¾ˆå¿™ã€‚
æˆ‘ï¼šé‚£ä½ è¯´ä¸‹ä½ å“ªå¤©æœ‰ç©ºï¼Ÿ
å¥¹ï¼šåˆ«çƒ¦æˆ‘äº†ï¼
"""
    print("ğŸ§  è¾“å…¥èŠå¤©æ–‡æœ¬ï¼š")
    print(chat)
    print("\nğŸ¤– æ¨èå›åº”ï¼š\n")
    print(suggest_replies_from_text(chat))
