import os
from openai import AzureOpenAI
from dotenv import load_dotenv

load_dotenv(dotenv_path=".env")

client = AzureOpenAI(
    api_key=os.getenv("AZURE_OPENAI_API_KEY"),
    api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
    azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT")
)

def generate_responses(user_input, style="æ¸©æŸ”é£", max_suggestions=3):
    prompt = (
        f"å¥¹å¯¹æˆ‘è¯´ï¼šâ€œ{user_input}â€\n"
        f"ä½ æ˜¯ä¸€ä¸ªæƒ…å•†å¾ˆé«˜ã€è¯´è¯åƒæœ‹å‹çš„AIï¼Œè¯·ç”¨ã€{style}ã€‘è¯­æ°”ï¼Œç”Ÿæˆ{max_suggestions}æ¡ç®€çŸ­é«˜æƒ…å•†å›åº”ï¼Œ"
        "æ¯æ¡25å­—ä»¥å†…ï¼Œåƒå¾®ä¿¡èŠå¤©è¯­æ°”ã€‚ä¸è¦è¯´å¤§é“ç†ã€‚\n"
        "è¿”å›æ ¼å¼ï¼š\n"
        "1. å¥å­ï¼ˆæ¨èæ˜Ÿçº§/ç†ç”±ï¼‰\n"
    )
    response = client.chat.completions.create(
        model=os.getenv("AZURE_DEPLOYMENT_NAME"),
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªå£è¯­è‡ªç„¶ã€æ‡‚å…±æƒ…ã€è¡¨è¾¾æ¸…æ™°çš„æƒ…æ„Ÿæ²Ÿé€šAIã€‚"},
            {"role": "user", "content": prompt}
        ],
        temperature=0.6,
        max_tokens=200
    )
    return response.choices[0].message.content

if __name__ == "__main__":
    user_text = "ä½ èƒ½ä¸èƒ½åˆ«çƒ¦æˆ‘ï¼Ÿ"
    style = "æ¸©æŸ”é£"
    print("ğŸ§  ç”¨æˆ·è¾“å…¥ï¼š", user_text)
    print("ğŸ¯ GPTç”Ÿæˆå›åº”ï¼š\n")
    print(generate_responses(user_text, style))
